---
title: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks
categories: [all, cv]
comments: true
usemathjax: true
---

[Zhu, Jun-Yan et al. IEEE International Conference on Computer Vision (2017):2242-2251.](https://arxiv.org/abs/1703.10593)

## 1. Introduction

Motivation:

- Having seen the paintings of Monet, We could easily imagine how would he render a scene without a side by side example of a Monet painting next to a photo of that scene.
- Previous research has produced powerful image-to-image translation system in the supervised setting. However, obtaining paired training data is expensive, typically requiring artistic authoring, and difficult, since the desired output cannot be well-defined.

Goal:

- To learn a system that can capture special characteristics of one image collection and figuring out how these characteristics could be translated into the other image collection, all in the absence of any paired training examples.
- Assume that there is some underlying relationship - for example, two images are just two different rederings of the same underlying world - and seek to learn that relationship.

Means:

- Given one set of images in doamin $$X$$ and a different set in domain $$Y$$, we can train a mapping $$G: X \rightarrow Y$$ s.t. the output $$\hat{y} = G(x), x \in X$$ is indistinguishable from $$y \in Y$$ by an adversary trained to classify $$\hat{y}$$ apart from $$y$$.
- However, doing so does not guarantee that $$x$$ and $$y$$ are paired in a meaningful way. Moreover, conventional training procedure often lead to mode collapse, where all input images map to the same output image and the optimizer stop progressing.
- Therefore, the objective needs "cycle consistency". Just like if we translate a sentence from English to French, and then translate it back from French to English, we should arrive back at the original sentence.
- Addition to the adversary losses on domain $$X$$ and $$Y$$: Given to translators $$G: X \rightarrow Y$$ and $$F: Y \rightarrow X$$, train $$G$$ and $$F$$ simultaneously with the default adversary losses, and add a cycle consistency loss that encourages $$F(G(x)) \approx x$$ and $$G(F(y)) \approx y$$.

## 2. Formulation

![Cycle Consistency Loss](../assets/img/2023-02-09-cycle-gan/cycle_consistency_loss.jpg)

### 2.1. Adversarial Loss

Apply adversarial losses to both mapping functions. For example, for the mapping function $$G: X \rightarrow Y$$ and its discriminator $$D_y$$, the objective is:

$$\mathcal{L}_{\text{GAN}}(G, D_y, X, Y) = \mathbb{E}_{y \sim p_{data}(y)}[\log D_y(y)] + \mathbb{E}_{x \sim p_{data}(x)}[\log (1 - D_y(y))] \tag{1}$$

where $$G$$ tries to generate images $$G(x)$$ that look similar to images from domain $$Y$$, while $$D_y$$ aims to distinguish between translated samples $$G(x)$$ and real samples $$y$$. Same applies to the mapping $$F: Y \rightarrow X$$.

### 2.2. Cycle Consistency Loss

In theory, if $$G$$ and $$F$$ are strictly stochastic functions, adversarial loss is fully capable of guiding the translator to produce outputs identical to the target domains. However, with large enough capacity, a network can map the same set of input images to any random permutation of images in the target domain, where any of the learned mappings can induce an output distribution that matches the target distribution. Therefore, a cycle consistency loss is needed to further constraint the space of possible mapping functions:

$$\mathcal{L}_{cyc}(G, F) = \mathbb{E}_{x \sim p_{data}(x)}[\Vert F(G(x)) - x \Vert]_1] + \mathbb{E}_{y \sim p_{data}(y)}[\Vert G(F(y)) - y \Vert]_1] \tag{2}$$

meaning that for each image $$y$$ from domain $$Y$$, mapping $$G$$ and $$F$$ should also satisfy *backward cycle consistency* $$y \rightarrow F(y) \rightarrow G(F(y)) \approx y$$.

### 2.3 Full Objective

Combining the adversarial losses and the cycle consistency loss, the full objective can be expressed as:

$$\begin{align*} \mathcal{L}(G, F, D_x, D_y) &= \mathcal{L}_{\text{GAN}}(G, D_y, X, Y) \\ &+ \mathcal{L}_{\text{GAN}}(F, D_x, Y, X) \\ &+ \lambda\mathcal{L}_{\text{cyc}}(G, F) \end{align*} \tag{3}$$

where $$\lambda$$ controls the relative importance of the two objectives. This is equivalent to solve for optimal mappings $$G^*$$ and $$F^*$$ where:

$$G^*, F^* = \arg\min_{G, F}\max_{D_x, D_y} \mathcal{L}(G, F, D_x, D_y) \tag{4}$$

From this perspective, the model can be viewed as a special case of "adversarial autoencoders", which use an adversarial loss to train the bottlenect layer of an autoencoder to match an arbitrary target distribution.

## 3. Implementation Details

## 4. Results
